{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [the original paper](https://arxiv.org/abs/1404.3606)\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "import timeit\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from chainer.functions import convolution_2d\n",
    "\n",
    "def steps(image_shape, filter_shape, step_shape):\n",
    "    \"\"\"\n",
    "    Generates feature map coordinates that filters visit\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_shape: tuple of ints\n",
    "        Image height / width\n",
    "    filter_shape: tuple of ints\n",
    "        Filter height / width\n",
    "    step_shape: tuple of ints\n",
    "        Step height / width\n",
    "    Returns\n",
    "    -------\n",
    "    ys: Map coordinates along y axis\n",
    "    xs: Map coordinates along x axis\n",
    "    \"\"\"\n",
    "    h, w = image_shape\n",
    "    fh, fw = filter_shape\n",
    "    sh, sw = step_shape\n",
    "\n",
    "    ys = range(0, h-fh+1, sh)\n",
    "    xs = range(0, w-fw+1, sw)\n",
    "    return ys, xs\n",
    "\n",
    "\n",
    "def components_to_filters(components, n_channels, filter_shape):\n",
    "    \"\"\"\n",
    "    | In PCANet, components of PCA are used as filter weights.\n",
    "    | This function reshapes PCA components so that\n",
    "      it can be used as networks filters\n",
    "    \"\"\"\n",
    "    n_filters = components.shape[0]\n",
    "    return components.reshape(n_filters, n_channels, *filter_shape)\n",
    "\n",
    "\n",
    "def output_shape(ys, xs):\n",
    "    return len(ys), len(xs)\n",
    "\n",
    "\n",
    "class Patches(object):\n",
    "    def __init__(self, image, filter_shape, step_shape):\n",
    "        assert(image.ndim == 2)\n",
    "\n",
    "        # should be either numpy.ndarray or cupy.ndarray\n",
    "        self.ndarray = type(image)\n",
    "        self.image = image\n",
    "        self.filter_shape = filter_shape\n",
    "\n",
    "        self.ys, self.xs = steps(image.shape[0:2], filter_shape, step_shape)\n",
    "\n",
    "    @property\n",
    "    def patches(self):\n",
    "        \"\"\"\n",
    "        Return image patches of shape\n",
    "        (n_patches, filter_height, filter_width)\n",
    "        \"\"\"\n",
    "        fh, fw = self.filter_shape\n",
    "        it = list(itertools.product(self.ys, self.xs))\n",
    "        patches = self.ndarray((len(it), fh, fw), dtype=self.image.dtype)\n",
    "        for i, (y, x) in enumerate(it):\n",
    "            patches[i, :, :] = self.image[y:y+fh, x:x+fw]\n",
    "        return patches\n",
    "\n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return output_shape(self.ys, self.xs)\n",
    "\n",
    "\n",
    "def atleast_4d(images):\n",
    "    \"\"\"Regard gray-scale images as 1-channel images\"\"\"\n",
    "    assert(np.ndim(images) == 3)\n",
    "    n, h, w = images.shape\n",
    "    return images.reshape(n, h, w, 1)\n",
    "\n",
    "\n",
    "def to_channels_first(images):\n",
    "    \"\"\"\n",
    "    Change image channel order from\n",
    "    :code:`(n_images, y, x, n_channels)` to\n",
    "    :code:`(n_images, n_channels, y, x)`\n",
    "    \"\"\"\n",
    "    # images.shape == (n_images, y, x, n_channels)\n",
    "    images = np.swapaxes(images, 1, 3)\n",
    "    images = np.swapaxes(images, 2, 3)\n",
    "    # images.shape == (n_images, n_channels, y, x)\n",
    "    return images\n",
    "\n",
    "\n",
    "def image_to_patch_vectors(image, filter_shape, step_shape):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.ndarray\n",
    "        Image to extract patch vectors\n",
    "    filter_shape: tuple of ints\n",
    "        The shape of a filter\n",
    "    step_shape: tuple of ints\n",
    "        Step height/width of a filter\n",
    "    Returns\n",
    "    -------\n",
    "    X: np.ndarray\n",
    "        A set of normalized and flattened patches\n",
    "    \"\"\"\n",
    "\n",
    "    X = Patches(image, filter_shape, step_shape).patches\n",
    "    # X.shape == (n_patches, filter_height, filter_width)\n",
    "\n",
    "    X = X.reshape(X.shape[0], -1)  # flatten each patch\n",
    "    X = X - X.mean(axis=1, keepdims=True)  # Remove mean from each patch.\n",
    "    return X  # \\overline{X}_i in the original paper\n",
    "\n",
    "\n",
    "def binarize(X):\n",
    "    \"\"\"\n",
    "    Binarize each element of :code:`X`\n",
    "    .. code::\n",
    "        X = [1 if X[i] > 0 else 0 for i in range(len(X))]\n",
    "    \"\"\"\n",
    "    X[X > 0] = 1\n",
    "    X[X <= 0] = 0\n",
    "    return X\n",
    "\n",
    "\n",
    "def binary_to_decimal(X):\n",
    "    \"\"\"\n",
    "    | This function takes :code:`X` of shape (n_images, L2, y, x) as an argument.\n",
    "    | Supporse that :code:`X[k]` (0 <= k < n_images) can be represented as\n",
    "    .. code-block:: none\n",
    "        X[k] = [map_k[0], map_k[1], ..., map_k[L2-1]]\n",
    "    where the shape of each map_k is (y, x).\n",
    "    Then we calculate\n",
    "    .. code-block:: none\n",
    "        a[0] * map_k[0] + a[1] * map_k[1] + ... + a[L2-1] * map_k[L2-1]\n",
    "    for each :code:`X[k]`, where :math:`a = [2^{L2-1}, 2^{L2-2}, ..., 2^{0}]`\n",
    "    Therefore, the output shape must be (n_images, y, x)\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: np.ndarray\n",
    "        Feature maps\n",
    "    \"\"\"\n",
    "    a = np.arange(X.shape[1])[::-1]\n",
    "    a = np.power(2, a)\n",
    "    return np.tensordot(X, a, axes=([1], [0]))\n",
    "\n",
    "\n",
    "def to_tuple_if_int(value):\n",
    "    \"\"\"\n",
    "    If int is given, duplicate it and return as a 2 element tuple.\n",
    "    \"\"\"\n",
    "    if isinstance(value, int):\n",
    "        return (value, value)\n",
    "    return value\n",
    "\n",
    "\n",
    "class PCANet(object):\n",
    "    def __init__(self, image_shape,\n",
    "                 filter_shape_l1, step_shape_l1, n_l1_output,\n",
    "                 filter_shape_l2, step_shape_l2, n_l2_output,\n",
    "                 filter_shape_pooling, step_shape_pooling):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_shape: int or sequence of ints\n",
    "            Input image shape.\n",
    "        filter_shape_l1: int or sequence of ints\n",
    "            The shape of the kernel in the first convolution layer.\n",
    "            If the value is int, a filter of the square shape is applied.\n",
    "            If you want to apply a filter of a different aspect ratio, just\n",
    "            pass a tuple of shape (height, width).\n",
    "        step_shape_l1: int or sequence of ints\n",
    "            The shape of kernel step in the first convolution layer.\n",
    "            If the value is int, a step of the square shape is applied.\n",
    "            If you want to apply a step of a different aspect ratio, just\n",
    "            pass a tuple of shape (height, width).\n",
    "        n_l1_output:\n",
    "            L1 in the original paper. The number of outputs obtained\n",
    "            from a set of input images.\n",
    "        filter_shape_l2: int or sequence of ints\n",
    "            The shape of the kernel in the second convolution layer.\n",
    "            If the value is int, a filter of the square shape is applied.\n",
    "            If you want to apply a filter of a different aspect ratio, just\n",
    "            pass a tuple of shape (height, width).\n",
    "        step_shape_l2: int or sequence of ints\n",
    "            The shape of kernel step in the second convolution layer.\n",
    "            If the value is int, a step of the square shape is applied.\n",
    "            If you want to apply a step of a different aspect ratio, just\n",
    "            pass a tuple of shape (height, width).\n",
    "        n_l2_output:\n",
    "            L2 in the original paper. The number of outputs obtained\n",
    "            from each L1 output.\n",
    "        filter_shape_pooling: int or sequence of ints\n",
    "            The shape of the filter in the pooling layer.\n",
    "        step_shape_pooling: int or sequence of ints\n",
    "            The shape of the filter step in the pooling layer.\n",
    "        \"\"\"\n",
    "\n",
    "        self.image_shape = to_tuple_if_int(image_shape)\n",
    "\n",
    "        self.filter_shape_l1 = to_tuple_if_int(filter_shape_l1)\n",
    "        self.step_shape_l1 = to_tuple_if_int(step_shape_l1)\n",
    "        self.n_l1_output = n_l1_output\n",
    "\n",
    "        self.filter_shape_l2 = to_tuple_if_int(filter_shape_l2)\n",
    "        self.step_shape_l2 = to_tuple_if_int(step_shape_l2)\n",
    "        self.n_l2_output = n_l2_output\n",
    "\n",
    "        self.filter_shape_pooling = to_tuple_if_int(filter_shape_pooling)\n",
    "        self.step_shape_pooling = to_tuple_if_int(step_shape_pooling)\n",
    "        self.n_bins = None  # TODO make n_bins specifiable\n",
    "\n",
    "        self.pca_l1 = IncrementalPCA(n_l1_output)\n",
    "        self.pca_l2 = IncrementalPCA(n_l2_output)\n",
    "\n",
    "    def histogram(self, binary_images):\n",
    "        \"\"\"\n",
    "        Separate a given image into blocks and calculate a histogram\n",
    "        in each block.\n",
    "        Supporse data in a block is in range [0, 3] and the acutual\n",
    "        values are\n",
    "        ::\n",
    "            [0 0 1]\n",
    "            [2 2 2]\n",
    "            [2 3 3]\n",
    "        | If default bins ``[-0.5 0.5 1.5 2.5 3.5]`` applied,\n",
    "          the histogram will be ``[2 1 4 2]``.\n",
    "        | If ``n_bins`` is specified, the range of data divided equally.\n",
    "        | For example, if the data is in range ``[0, 3]`` and ``n_bins = 2``,\n",
    "        | bins will be ``[-0.5 1.5 3.5]`` and the histogram will be ``[3 6]``.\n",
    "        \"\"\"\n",
    "\n",
    "        k = pow(2, self.n_l2_output)\n",
    "        if self.n_bins is None:\n",
    "            self.n_bins = k + 1\n",
    "        bins = np.linspace(-0.5, k - 0.5, self.n_bins)\n",
    "\n",
    "        def bhist(image):\n",
    "            # calculate Bhist(T) in the original paper\n",
    "            ps = Patches(\n",
    "                image,\n",
    "                self.filter_shape_pooling,\n",
    "                self.step_shape_pooling).patches\n",
    "\n",
    "            H = [np.histogram(p.flatten(), bins)[0] for p in ps]\n",
    "            return np.concatenate(H)\n",
    "        return np.vstack([bhist(image) for image in binary_images])\n",
    "\n",
    "    def process_input(self, images):\n",
    "        assert(np.ndim(images) >= 3)\n",
    "        assert(images.shape[1:3] == self.image_shape)\n",
    "        if np.ndim(images) == 3:\n",
    "            # forcibly convert to multi-channel images\n",
    "            images = atleast_4d(images)\n",
    "        images = to_channels_first(images)\n",
    "        return images\n",
    "\n",
    "    def fit(self, images):\n",
    "        \"\"\"\n",
    "        Train PCANet\n",
    "        Parameters\n",
    "        ----------\n",
    "        images: np.ndarray\n",
    "            | Color / grayscale images of shape\n",
    "            | (n_images, height, width, n_channels) or\n",
    "            | (n_images, height, width)\n",
    "        \"\"\"\n",
    "        images = self.process_input(images)\n",
    "        # images.shape == (n_images, n_channels, y, x)\n",
    "\n",
    "        for image in images:\n",
    "            X = []\n",
    "            for channel in image:\n",
    "                patches = image_to_patch_vectors(\n",
    "                    channel,\n",
    "                    self.filter_shape_l1,\n",
    "                    self.step_shape_l1\n",
    "                )\n",
    "                X.append(patches)\n",
    "            patches = np.hstack(X)\n",
    "            # patches.shape = (n_patches, n_patches * vector length)\n",
    "            self.pca_l1.partial_fit(patches)\n",
    "\n",
    "        filters_l1 = components_to_filters(\n",
    "            self.pca_l1.components_,\n",
    "            n_channels=images.shape[1],\n",
    "            filter_shape=self.filter_shape_l1,\n",
    "        )\n",
    "\n",
    "\n",
    "        images = convolution_2d(\n",
    "            images,\n",
    "            filters_l1,\n",
    "            stride=self.step_shape_l1\n",
    "        ).data\n",
    "        \n",
    "\n",
    "        # images.shape == (n_images, L1, y, x)\n",
    "        images = images.reshape(-1, *images.shape[2:4])\n",
    "\n",
    "        for image in images:\n",
    "            patches = image_to_patch_vectors(\n",
    "                image,\n",
    "                self.filter_shape_l2,\n",
    "                self.step_shape_l2\n",
    "            )\n",
    "            self.pca_l2.partial_fit(patches)\n",
    "        return self\n",
    "\n",
    "    def transform(self, images):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        images: np.ndarray\n",
    "            | Color / grayscale images of shape\n",
    "            | (n_images, height, width, n_channels) or\n",
    "            | (n_images, height, width)\n",
    "        Returns\n",
    "        -------\n",
    "        X: np.ndarray\n",
    "            A set of feature vectors of shape (n_images, n_features)\n",
    "            where :code:`n_features` is determined by the hyperparameters\n",
    "        \"\"\"\n",
    "        images = self.process_input(images)\n",
    "        # images.shape == (n_images, n_channels, y, x)\n",
    "\n",
    "        filters_l1 = components_to_filters(\n",
    "            self.pca_l1.components_,\n",
    "            n_channels=images.shape[1],\n",
    "            filter_shape=self.filter_shape_l1,\n",
    "        )\n",
    "\n",
    "        filters_l2 = components_to_filters(\n",
    "            self.pca_l2.components_,\n",
    "            n_channels=1,\n",
    "            filter_shape=self.filter_shape_l2\n",
    "        )\n",
    "\n",
    "        images = convolution_2d(\n",
    "            images,\n",
    "            filters_l1,\n",
    "            stride=self.step_shape_l1\n",
    "        ).data\n",
    "\n",
    "        images = np.swapaxes(images, 0, 1)\n",
    "\n",
    "        # L1.shape == (L1, n_images, y, x)\n",
    "        # iterate over each L1 output\n",
    "\n",
    "        X = []\n",
    "        for maps in images:\n",
    "            n_images, h, w = maps.shape\n",
    "            maps = convolution_2d(\n",
    "                maps.reshape(n_images, 1, h, w),  # 1 channel images\n",
    "                filters_l2,\n",
    "                stride=self.step_shape_l2\n",
    "            ).data\n",
    "\n",
    "            # maps.shape == (n_images, L2, y, x) right here\n",
    "            maps = binarize(maps)\n",
    "            maps = binary_to_decimal(maps)\n",
    "            # maps.shape == (n_images, y, x)\n",
    "            x = self.histogram(maps)\n",
    "\n",
    "            # x is a set of feature vectors.\n",
    "            # The shape of x is (n_images, vector length)\n",
    "            X.append(x)\n",
    "\n",
    "        # concatenate over L1\n",
    "        X = np.hstack(X)\n",
    "\n",
    "        X = X.astype(np.float64)\n",
    "\n",
    "        # The shape of X is (n_images, L1 * vector length)\n",
    "        return X\n",
    "\n",
    "    def validate_structure(self):\n",
    "        \"\"\"\n",
    "        Check that the filter visits all pixels of input images without\n",
    "        dropping any information.\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError:\n",
    "            if the network structure does not satisfy the above constraint.\n",
    "        \"\"\"\n",
    "        def is_valid_(input_shape, filter_shape, step_shape):\n",
    "            ys, xs = steps(input_shape, filter_shape, step_shape)\n",
    "            fh, fw = filter_shape\n",
    "            h, w = input_shape\n",
    "            if ys[-1]+fh != h or xs[-1]+fw != w:\n",
    "                raise ValueError(\"Invalid network structure.\")\n",
    "            return output_shape(ys, xs)\n",
    "\n",
    "        output_shape_l1 = is_valid_(self.image_shape,\n",
    "                                    self.filter_shape_l1,\n",
    "                                    self.step_shape_l1)\n",
    "        output_shape_l2 = is_valid_(output_shape_l1,\n",
    "                                    self.filter_shape_l2,\n",
    "                                    self.step_shape_l2)\n",
    "        is_valid_(\n",
    "            output_shape_l2,\n",
    "            self.filter_shape_pooling,\n",
    "            self.filter_shape_pooling\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import *\n",
    "from scipy.misc import imresize\n",
    "\n",
    "#load MNIST\n",
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_set_preprocessing(X, y, batch_ratio = 1, pad_size=2, pad_method='constant'):\n",
    "    \n",
    "    batch_size = (int)(X.shape[0]*batch_ratio)\n",
    "    \n",
    "    #order = np.array(range(X_pad.shape[0]))\n",
    "    #np.random.shuffle(order)\n",
    "    #X_pad_shuffle = X_pad[order]\n",
    "    #y_shuffle = y[order]\n",
    "    X_pad_shuffle = X\n",
    "    y_shuffle = y\n",
    "\n",
    "    X_train_batch = ((X_pad_shuffle[0:batch_size, :, :]).astype('float32'))/255\n",
    "    y_train_batch = y_shuffle[0:batch_size,]\n",
    "    X_train_batch = X_train_batch.reshape(X_train_batch.shape[0], X_train_batch.shape[1], X_train_batch.shape[2], 1)\n",
    "    \n",
    "    return X_train_batch, y_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_batch = image_set_preprocessing(X_train_raw, y_train_raw, batch_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_set):\n",
    "    images_train, y_train = train_set\n",
    "\n",
    "    pcanet = PCANet(\n",
    "        image_shape=28,\n",
    "        filter_shape_l1=5, step_shape_l1=1, n_l1_output=8,\n",
    "        filter_shape_l2=5, step_shape_l2=1, n_l2_output=4,\n",
    "        filter_shape_pooling=5, step_shape_pooling=5\n",
    "    )\n",
    "\n",
    "    pcanet.validate_structure()\n",
    "\n",
    "    t1 = timeit.default_timer()\n",
    "    pcanet.fit(images_train)\n",
    "    t2 = timeit.default_timer()\n",
    "\n",
    "    train_time = t2 - t1\n",
    "\n",
    "    t1 = timeit.default_timer()\n",
    "    X_train = pcanet.transform(images_train)\n",
    "    t2 = timeit.default_timer()\n",
    "\n",
    "    transform_time = t2 - t1\n",
    "\n",
    "    classifier = SVC(C=10)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return pcanet, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcanet, classifier = train((X_train, y_train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pcanet, classifier, test_set):\n",
    "    images_test, y_test = test_set\n",
    "\n",
    "    X_test = pcanet.transform(images_test)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test_batch = image_set_preprocessing(X_test_raw, y_test_raw, batch_ratio = 1)\n",
    "y_pred, y_test = test(pcanet, classifier, (X_test, y_test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9848"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n",
      "/Applications/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "n_sample_train = X_train.shape[0]\n",
    "X_train_new = np.zeros((n_sample_train, 28, 28))\n",
    "\n",
    "for i in range(n_sample_train):\n",
    "    img = X_train[i].reshape(h,w)\n",
    "    X_train_new[i] = imresize(img, [28,28], mode='F')/255\n",
    "    \n",
    "n_sample_test = X_test.shape[0]\n",
    "X_test_new = np.zeros((n_sample_test, 28, 28))\n",
    "\n",
    "for i in range(n_sample_test):\n",
    "    img = X_test[i].reshape(h,w)\n",
    "    X_test_new[i] = imresize(img, [28,28], mode='F')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcanet_face, classifier_face = train((X_train_new, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_test = test(pcanet_face, classifier_face, (X_test_new, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6180124223602484"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
